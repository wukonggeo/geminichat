import os
import time
import random
import streamlit as st

from PIL import Image
from pathlib import Path
from google import genai
from google.genai import types

st.set_page_config(
    page_title="Chat To XYthing",
    page_icon="ğŸ”¥",
    menu_items={
        'About': "# Test Demo"
    }
)
st.title('Upload Image And Ask')
model_options = {
    'gemini-2.0-pro-exp-02-05': "Pro",
    'gemini-2.0-flash': "Flash",
    'gemini-2.0-flash-exp': "Vison",
    'gemini-2.5-flash-preview-05-20': "Think-Pre",
    'gemini-2.5-flash': "Think-Flash",
    "gemini-2.5-pro":"Think-PRO"
    }
default_index = list(model_options.keys()).index('gemini-2.5-pro')
BASE_PATH = Path(__file__).resolve().parents[1] / 'resource'

# åˆå§‹åŒ–çŠ¶æ€ä¿¡æ¯
if "history_pic" not in st.session_state:
    st.session_state.history_pic = []
if 'app_key' not in st.session_state:
    st.session_state.app_key = None
if st.session_state.app_key is None:
    app_key = st.text_input("Your Gemini App Key", type='password', key="gemini_key_input")
    if app_key:
        st.session_state.app_key = app_key
        st.rerun()
if 'data_file' not in st.session_state:
    st.session_state['data_file'] = False

# ä¾§è¾¹çŠ¶æ€æ 
with st.sidebar:
    if st.button("Clear Chat Window", use_container_width = True, type="primary"):
        st.session_state.history_pic  = []
        st.rerun()
    selected_model = st.selectbox(
        "Select Model",
        options=list(model_options.keys()),
        format_func=lambda x: model_options[x],  #æ˜¾ç¤ºçš„åç§°
        index=default_index
        )
try:
    # gemini-pro-vision
    app_key = st.session_state.app_key
    if app_key is None:
        st.warning("Please Put Your Gemini App Key First.")
    else:
        if len(app_key) < 40:
            client = genai.Client(api_key = app_key)
        else:
            client = genai.Client(api_key = app_key, vertexai=True)
    config = types.GenerateContentConfig(
      thinking_config=types.ThinkingConfig(
        include_thoughts=True
      )
    )
except AttributeError as e:
    st.warning("Please Put Your Gemini App Key First.")


def clear_state():
    st.session_state.history_pic = []


def convert_history_model(history_list):
    model_history = []
    if len(st.session_state.history_pic) > 0:
        for message in st.session_state.history_pic:
            data_dict = {}
            role = "model" if message.role == "assistant" else message.role
            if "text" in message:
                content = message["text"]
            elif "image" in message:
                content = {
                    "mime_type": "image/png",
                    "data": message["image"],
                }
            data_dict[role] = content
            model_history.append(data_dict)
    return model_history


def convert_history_gemini():
    model_history = []
    if len(st.session_state.history_pic) > 0:
        for message in st.session_state.history_pic:
            content = message["text"]
            if "image" in message and message['image'] is not None:
                content = [
                    message["text"],
                    types.Part.from_bytes(data= message['image'], mime_type="image/png"),
                ]
            if message['role'] == "assistant":
                # data = types.Content(role='model',parts=[types.Part.from_text(text=content)],)
                model_history.append(types.ModelContent(content))
            else:
                # data = types.Content(role='user',parts=[types.Part.from_text(text=content)],)
                 model_history.append(types.UserContent(content))
    return model_history


def show_message(prompt, image, file, loading_str):
    global data_cache
    if image and not st.session_state.data_file:
        prompt = [prompt, image]
        st.session_state.data_file = True
    if file and not st.session_state.data_file:
        prompt = [prompt, file]
        st.session_state.data_file = True
    history = convert_history_gemini()
    chat = client.chats.create(model=selected_model, config=config, history=history)
    # å¼€å¯å¯¹è¯
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown(loading_str)
        # åˆå§‹åŒ–å˜é‡
        image_count = 0
        full_response = "#### æ­£å¼å›ç­”ï¼š\n" 
        thought_text = "#### æ€ç»´é“¾ï¼š\n"
        image_data = None
        try:
            for chunk in chat.send_message_stream(prompt):
                word_count = 0
                random_int = random.randint(10, 20)
                if not chunk.candidates or not chunk.candidates[0].content or not chunk.candidates[0].content.parts:
                    continue
                for part in chunk.candidates[0].content.parts:
                    if part.inline_data:
                        image_data = part.inline_data.data
                        mime_type = part.inline_data.mime_type
                        # æ£€æŸ¥ image_data æ˜¯å¦ä¸ºç©ºæˆ–ä¸º None
                        if image_data:
                            try:
                                output_file = f"genai_image_{image_count}.{mime_type.split('/')[-1]}"
                                st.image(image_data, caption=f"Generated Image {output_file}", use_column_width=True)
                                image_count += 1
                            except Exception as e:
                                st.error(f"Error displaying image: {e}")
                    elif part.thought:
                        thought_text += part.text
                        message_placeholder.markdown(thought_text + "_")
                    elif part.text:
                        full_response += part.text
                        message_placeholder.markdown(full_response + "_")
            # ç»“æŸæµå¼è¾“å‡ºåä¸€æ¬¡æ€§å…¨éƒ¨åˆ·æ–°
            # if thought_text:
            #     message_placeholder.markdown(thought_text)
            # elif full_response:
            #     message_placeholder.markdown(full_response)
        except Exception as e:
            st.exception(e)
        full_response = thought_text + full_response
        message_placeholder.markdown(full_response)
        # åªæœ‰å›ç­”æˆåŠŸæ—¶ï¼Œæ›´æ–°å†å²æ¶ˆæ¯
        st.session_state.history_pic.append({"role": "user", "text": prompt})
        if image_data:
            st.session_state.history_pic.append({"role": "assistant", "text": full_response, "image": image_data})
        else:
             #åªä¿å­˜æ–‡æœ¬ï¼Œå›¾åƒè®¾ç½®ä¸ºNone
            st.session_state.history_pic.append({"role": "assistant", "text": full_response, "image": None})


def save_uploaded_pdf(uploaded_file, save_path):
  """
  ä¿å­˜ä¸Šä¼ çš„PDFæ–‡ä»¶åˆ°æœ¬åœ°ã€‚
  """
  try:
    with open(save_path, "wb") as f:  # ä»¥äºŒè¿›åˆ¶å†™å…¥æ¨¡å¼æ‰“å¼€æ–‡ä»¶
      f.write(uploaded_file.getbuffer())  # å°†ä¸Šä¼ æ–‡ä»¶çš„å†…å®¹å†™å…¥æ–‡ä»¶
    return True
  except Exception as e:
    print(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")  # æ‰“å°é”™è¯¯ä¿¡æ¯ï¼Œæ–¹ä¾¿è°ƒè¯•
    return False


def clear_other_pdfs(dir_path, keep_filename=None):
    """åˆ é™¤æŒ‡å®šç›®å½•ä¸‹é™¤ keep_filename å¤–çš„æ‰€æœ‰pdfæ–‡ä»¶ã€‚"""
    pdf_files = dir_path.glob("*.pdf")
    for f in pdf_files:
        if keep_filename is not None and f.name == keep_filename:
            continue
        try:
            f.unlink()
        except Exception as e:
            st.warning(f"åˆ é™¤ {f} å¤±è´¥: {e}")


@st.cache_data(show_spinner=False)
def input_file(file):
    # uploaded_file = st.file_uploader('è¯·æ‰“å¼€ä¸€ä¸ªæ–‡ä»¶', type=['pdf'], accept_multiple_files=True)
    file_save_path = None
    if file:
        clear_other_pdfs(BASE_PATH, keep_filename=file.name)
        file_save_path = BASE_PATH / file.name
        save_uploaded_pdf(file, file_save_path)
        st.session_state['data_file'] = False
    return file_save_path


image, file = None, None
if "app_key" in st.session_state and st.session_state.app_key is not None:
    uploaded_file = st.file_uploader("è¯·é€‰æ‹©æœ¬åœ°PDFæˆ–å›¾ç‰‡...", type=["pdf", "jpg", "png", "jpeg", "gif"], label_visibility='collapsed', on_change = clear_state)
    if uploaded_file is not None:
        if uploaded_file.type == "application/pdf":
            file_path = input_file(uploaded_file)
            try:
                # 'name' å±æ€§æ˜¯ä¸Šä¼ æ–‡ä»¶çš„åŸå§‹åç§°ï¼Œå¯ä»¥ä½œä¸ºå±•ç¤ºåç§° uploaded_file.name
                file = client.files.upload(file=uploaded_file, config={'display_name':'reference materials' })
                st.success(f"æ–‡ä»¶ '{uploaded_file.name}' ä¸Šä¼ æˆåŠŸï¼")
                st.write(f"Google GenAI File ID: {file.name}")
            except Exception as e:
                st.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
                # æ‰“å°è¯¦ç»†é”™è¯¯ä»¥å¸®åŠ©è°ƒè¯•
                st.exception(e)
        else:
            image = Image.open(uploaded_file).convert('RGB')
            image_bytes = image.tobytes()
            width, height = image.size
            resized_img = image.resize((128, int(height/(width/128))), Image.LANCZOS)
            st.image(resized_img)

if len(st.session_state.history_pic) > 0:
    for item in st.session_state.history_pic:
        image_count = 0
        with st.chat_message(item["role"]):
            if "text" in item and item["text"]:
                st.markdown(item["text"])
            if "image" in item and item["image"]:
                st.image(item["image"], caption=f"Generated Image_{image_count}", use_column_width=True)
                image_count += 1

if "app_key" in st.session_state:
    if prompt := st.chat_input("è¯·è¾“å…¥é—®é¢˜"):
        if image is None:
            pass
        prompt = prompt.replace('\n', '  \n')
        with st.chat_message("user"):
            st.markdown(prompt)
        show_message(prompt, image, file, "Thinking...")
